<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<title>OpenCV: Image Thresholding</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.2.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<script type="text/javascript">
//<![CDATA[
function getLabelName(innerHTML) {
    var str = innerHTML.toLowerCase();
    // Replace all '+' with 'p'
    str = str.split('+').join('p');
    // Replace all ' ' with '_'
    str = str.split(' ').join('_');
    // Replace all '#' with 'sharp'
    str = str.split('#').join('sharp');
    // Replace other special characters with 'ascii' + code
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        if (!(charCode == 95 || (charCode > 96 && charCode < 123) || (charCode > 47 && charCode < 58)))
            str = str.substr(0, i) + 'ascii' + charCode + str.substr(i + 1);
    }
    return str;
}
function addToggle() {
    var $getDiv = $('div.newInnerHTML').last();
    var buttonName = $getDiv.html();
    var label = getLabelName(buttonName.trim());
    $getDiv.attr("title", label);
    $getDiv.hide();
    $getDiv = $getDiv.next();
    $getDiv.attr("class", "toggleable_div label_" + label);
    $getDiv.hide();
}
//]]>
</script>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d6/d00/tutorial_py_root.html">OpenCV-Python Tutorials</a></li><li class="navelem"><a class="el" href="../../d2/d96/tutorial_py_table_of_contents_imgproc.html">Image Processing in OpenCV</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Image Thresholding </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Goal </h2>
<ul>
<li>In this tutorial, you will learn Simple thresholding, Adaptive thresholding, Otsu's thresholding etc.</li>
<li>You will learn these functions : <b>cv2.threshold</b>, <b>cv2.adaptiveThreshold</b> etc.</li>
</ul>
<h2>Simple Thresholding </h2>
<p>Here, the matter is straight forward. If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value (may be black). The function used is <b>cv2.threshold</b>. First argument is the source image, which <b>should be a grayscale image</b>. Second argument is the threshold value which is used to classify the pixel values. Third argument is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value. OpenCV provides different styles of thresholding and it is decided by the fourth parameter of the function. Different types are:</p>
<ul>
<li>cv2.THRESH_BINARY</li>
<li>cv2.THRESH_BINARY_INV</li>
<li>cv2.THRESH_TRUNC</li>
<li>cv2.THRESH_TOZERO</li>
<li>cv2.THRESH_TOZERO_INV</li>
</ul>
<p>Documentation clearly explain what each type is meant for. Please check out the documentation.</p>
<p>Two outputs are obtained. First one is a <b>retval</b> which will be explained later. Second output is our <b>thresholded image</b>.</p>
<p>Code : </p><div class="fragment"><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">img = cv2.imread(<span class="stringliteral">&#39;gradient.png&#39;</span>,0)</div><div class="line">ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)</div><div class="line">ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)</div><div class="line">ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)</div><div class="line">ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)</div><div class="line">ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)</div><div class="line"></div><div class="line">titles = [<span class="stringliteral">&#39;Original Image&#39;</span>,<span class="stringliteral">&#39;BINARY&#39;</span>,<span class="stringliteral">&#39;BINARY_INV&#39;</span>,<span class="stringliteral">&#39;TRUNC&#39;</span>,<span class="stringliteral">&#39;TOZERO&#39;</span>,<span class="stringliteral">&#39;TOZERO_INV&#39;</span>]</div><div class="line">images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]</div><div class="line"></div><div class="line"><span class="keywordflow">for</span> i <span class="keywordflow">in</span> xrange(6):</div><div class="line">    plt.subplot(2,3,i+1),plt.imshow(images[i],<span class="stringliteral">&#39;gray&#39;</span>)</div><div class="line">    plt.title(titles[i])</div><div class="line">    plt.xticks([]),plt.yticks([])</div><div class="line"></div><div class="line">plt.show()</div></div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd>To plot multiple images, we have used plt.subplot() function. Please checkout Matplotlib docs for more details.</dd></dl>
<p>Result is given below :</p>
<div class="image">
<img src="../../threshold.jpg" alt="threshold.jpg"/>
<div class="caption">
image</div></div>
 <h2>Adaptive Thresholding </h2>
<p>In the previous section, we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas. In that case, we go for adaptive thresholding. In this, the algorithm calculate the threshold for a small regions of the image. So we get different thresholds for different regions of the same image and it gives us better results for images with varying illumination.</p>
<p>It has three ‘special’ input params and only one output argument.</p>
<p><b>Adaptive Method</b> - It decides how thresholding value is calculated.</p><ul>
<li>cv2.ADAPTIVE_THRESH_MEAN_C : threshold value is the mean of neighbourhood area.</li>
<li>cv2.ADAPTIVE_THRESH_GAUSSIAN_C : threshold value is the weighted sum of neighbourhood values where weights are a gaussian window.</li>
</ul>
<p><b>Block Size</b> - It decides the size of neighbourhood area.</p>
<p><b>C</b> - It is just a constant which is subtracted from the mean or weighted mean calculated.</p>
<p>Below piece of code compares global thresholding and adaptive thresholding for an image with varying illumination: </p><div class="fragment"><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">img = cv2.imread(<span class="stringliteral">&#39;sudoku.png&#39;</span>,0)</div><div class="line">img = cv2.medianBlur(img,5)</div><div class="line"></div><div class="line">ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)</div><div class="line">th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\</div><div class="line">            cv2.THRESH_BINARY,11,2)</div><div class="line">th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\</div><div class="line">            cv2.THRESH_BINARY,11,2)</div><div class="line"></div><div class="line">titles = [<span class="stringliteral">&#39;Original Image&#39;</span>, <span class="stringliteral">&#39;Global Thresholding (v = 127)&#39;</span>,</div><div class="line">            <span class="stringliteral">&#39;Adaptive Mean Thresholding&#39;</span>, <span class="stringliteral">&#39;Adaptive Gaussian Thresholding&#39;</span>]</div><div class="line">images = [img, th1, th2, th3]</div><div class="line"></div><div class="line"><span class="keywordflow">for</span> i <span class="keywordflow">in</span> xrange(4):</div><div class="line">    plt.subplot(2,2,i+1),plt.imshow(images[i],<span class="stringliteral">&#39;gray&#39;</span>)</div><div class="line">    plt.title(titles[i])</div><div class="line">    plt.xticks([]),plt.yticks([])</div><div class="line">plt.show()</div></div><!-- fragment --><p> Result :</p>
<div class="image">
<img src="../../ada_threshold.jpg" alt="ada_threshold.jpg"/>
<div class="caption">
image</div></div>
 <h2>Otsu’s Binarization </h2>
<p>In the first section, I told you there is a second parameter <b>retVal</b>. Its use comes when we go for Otsu’s Binarization. So what is it?</p>
<p>In global thresholding, we used an arbitrary value for threshold value, right? So, how can we know a value we selected is good or not? Answer is, trial and error method. But consider a <b>bimodal image</b> (<em>In simple words, bimodal image is an image whose histogram has two peaks</em>). For that image, we can approximately take a value in the middle of those peaks as threshold value, right ? That is what Otsu binarization does. So in simple words, it automatically calculates a threshold value from image histogram for a bimodal image. (For images which are not bimodal, binarization won’t be accurate.)</p>
<p>For this, our <a class="el" href="../../d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57" title="Applies a fixed-level threshold to each array element. ">cv2.threshold()</a> function is used, but pass an extra flag, cv2.THRESH_OTSU. <b>For threshold value, simply pass zero</b>. Then the algorithm finds the optimal threshold value and returns you as the second output, retVal. If Otsu thresholding is not used, retVal is same as the threshold value you used.</p>
<p>Check out below example. Input image is a noisy image. In first case, I applied global thresholding for a value of 127. In second case, I applied Otsu’s thresholding directly. In third case, I filtered image with a 5x5 gaussian kernel to remove the noise, then applied Otsu thresholding. See how noise filtering improves the result. </p><div class="fragment"><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">img = cv2.imread(<span class="stringliteral">&#39;noisy2.png&#39;</span>,0)</div><div class="line"></div><div class="line"><span class="comment"># global thresholding</span></div><div class="line">ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)</div><div class="line"></div><div class="line"><span class="comment"># Otsu&#39;s thresholding</span></div><div class="line">ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)</div><div class="line"></div><div class="line"><span class="comment"># Otsu&#39;s thresholding after Gaussian filtering</span></div><div class="line">blur = cv2.GaussianBlur(img,(5,5),0)</div><div class="line">ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)</div><div class="line"></div><div class="line"><span class="comment"># plot all the images and their histograms</span></div><div class="line">images = [img, 0, th1,</div><div class="line">          img, 0, th2,</div><div class="line">          blur, 0, th3]</div><div class="line">titles = [<span class="stringliteral">&#39;Original Noisy Image&#39;</span>,<span class="stringliteral">&#39;Histogram&#39;</span>,<span class="stringliteral">&#39;Global Thresholding (v=127)&#39;</span>,</div><div class="line">          <span class="stringliteral">&#39;Original Noisy Image&#39;</span>,<span class="stringliteral">&#39;Histogram&#39;</span>,<span class="stringliteral">&quot;Otsu&#39;s Thresholding&quot;</span>,</div><div class="line">          <span class="stringliteral">&#39;Gaussian filtered Image&#39;</span>,<span class="stringliteral">&#39;Histogram&#39;</span>,<span class="stringliteral">&quot;Otsu&#39;s Thresholding&quot;</span>]</div><div class="line"></div><div class="line"><span class="keywordflow">for</span> i <span class="keywordflow">in</span> xrange(3):</div><div class="line">    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],<span class="stringliteral">&#39;gray&#39;</span>)</div><div class="line">    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])</div><div class="line">    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)</div><div class="line">    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])</div><div class="line">    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],<span class="stringliteral">&#39;gray&#39;</span>)</div><div class="line">    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])</div><div class="line">plt.show()</div></div><!-- fragment --><p> Result :</p>
<div class="image">
<img src="../../otsu.jpg" alt="otsu.jpg"/>
<div class="caption">
image</div></div>
 <h3>How Otsu's Binarization Works?</h3>
<p>This section demonstrates a Python implementation of Otsu's binarization to show how it works actually. If you are not interested, you can skip this.</p>
<p>Since we are working with bimodal images, Otsu's algorithm tries to find a threshold value (t) which minimizes the <b>weighted within-class variance</b> given by the relation :</p>
<p class="formulaDsp">
\[\sigma_w^2(t) = q_1(t)\sigma_1^2(t)+q_2(t)\sigma_2^2(t)\]
</p>
<p>where</p>
<p class="formulaDsp">
\[q_1(t) = \sum_{i=1}^{t} P(i) \quad \&amp; \quad q_1(t) = \sum_{i=t+1}^{I} P(i)\]
</p>
 <p class="formulaDsp">
\[\mu_1(t) = \sum_{i=1}^{t} \frac{iP(i)}{q_1(t)} \quad \&amp; \quad \mu_2(t) = \sum_{i=t+1}^{I} \frac{iP(i)}{q_2(t)}\]
</p>
 <p class="formulaDsp">
\[\sigma_1^2(t) = \sum_{i=1}^{t} [i-\mu_1(t)]^2 \frac{P(i)}{q_1(t)} \quad \&amp; \quad \sigma_2^2(t) = \sum_{i=t+1}^{I} [i-\mu_1(t)]^2 \frac{P(i)}{q_2(t)}\]
</p>
<p>It actually finds a value of t which lies in between two peaks such that variances to both classes are minimum. It can be simply implemented in Python as follows: </p><div class="fragment"><div class="line">img = cv2.imread(<span class="stringliteral">&#39;noisy2.png&#39;</span>,0)</div><div class="line">blur = cv2.GaussianBlur(img,(5,5),0)</div><div class="line"></div><div class="line"><span class="comment"># find normalized_histogram, and its cumulative distribution function</span></div><div class="line">hist = cv2.calcHist([blur],[0],<span class="keywordtype">None</span>,[256],[0,256])</div><div class="line">hist_norm = hist.ravel()/hist.max()</div><div class="line">Q = hist_norm.cumsum()</div><div class="line"></div><div class="line">bins = np.arange(256)</div><div class="line"></div><div class="line">fn_min = np.inf</div><div class="line">thresh = -1</div><div class="line"></div><div class="line"><span class="keywordflow">for</span> i <span class="keywordflow">in</span> xrange(1,256):</div><div class="line">    p1,p2 = np.hsplit(hist_norm,[i]) <span class="comment"># probabilities</span></div><div class="line">    q1,q2 = Q[i],Q[255]-Q[i] <span class="comment"># cum sum of classes</span></div><div class="line">    b1,b2 = np.hsplit(bins,[i]) <span class="comment"># weights</span></div><div class="line"></div><div class="line">    <span class="comment"># finding means and variances</span></div><div class="line">    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2</div><div class="line">    v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2</div><div class="line"></div><div class="line">    <span class="comment"># calculates the minimization function</span></div><div class="line">    fn = v1*q1 + v2*q2</div><div class="line">    <span class="keywordflow">if</span> fn &lt; fn_min:</div><div class="line">        fn_min = fn</div><div class="line">        thresh = i</div><div class="line"></div><div class="line"><span class="comment"># find otsu&#39;s threshold value with OpenCV function</span></div><div class="line">ret, otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)</div><div class="line"><span class="keywordflow">print</span> thresh,ret</div></div><!-- fragment --><p> *(Some of the functions may be new here, but we will cover them in coming chapters)*</p>
<h2>Additional Resources </h2>
<ol type="1">
<li>Digital Image Processing, Rafael C. Gonzalez</li>
</ol>
<h2>Exercises </h2>
<ol type="1">
<li>There are some optimizations available for Otsu's binarization. You can search and implement it. </li>
</ol>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Dec 23 2016 13:00:25 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.12
</small></address>
<script type="text/javascript">
//<![CDATA[
function addButton(label, buttonName) {
    var b = document.createElement("BUTTON");
    b.innerHTML = buttonName;
    b.setAttribute('class', 'toggleable_button label_' + label);
    b.onclick = function() {
        $('.toggleable_button').css({
            border: '2px outset',
            'border-radius': '4px'
        });
        $('.toggleable_button.label_' + label).css({
            border: '2px inset',
            'border-radius': '4px'
        });
        $('.toggleable_div').css('display', 'none');
        $('.toggleable_div.label_' + label).css('display', 'block');
    };
    b.style.border = '2px outset';
    b.style.borderRadius = '4px';
    b.style.margin = '2px';
    return b;
}
function buttonsToAdd($elements, $heading, $type) {
    if ($elements.length === 0) {
        $elements = $("" + $type + ":contains(" + $heading.html() + ")").parent().prev("div.newInnerHTML");
    }
    var arr = jQuery.makeArray($elements);
    var seen = {};
    arr.forEach(function(e) {
        var txt = e.innerHTML;
        if (!seen[txt]) {
            $button = addButton(e.title, txt);
            if (Object.keys(seen).length == 0) {
                var linebreak1 = document.createElement("br");
                var linebreak2 = document.createElement("br");
                ($heading).append(linebreak1);
                ($heading).append(linebreak2);
            }
            ($heading).append($button);
            seen[txt] = true;
        }
    });
    return;
}
$("h2").each(function() {
    $heading = $(this);
    $smallerHeadings = $(this).nextUntil("h2").filter("h3").add($(this).nextUntil("h2").find("h3"));
    if ($smallerHeadings.length) {
        $smallerHeadings.each(function() {
            var $elements = $(this).nextUntil("h3").filter("div.newInnerHTML");
            buttonsToAdd($elements, $(this), "h3");
        });
    } else {
        var $elements = $(this).nextUntil("h2").filter("div.newInnerHTML");
        buttonsToAdd($elements, $heading, "h2");
    }
});
$(".toggleable_button").first().click();
var $clickDefault = $('.toggleable_button.label_python').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
$clickDefault = $('.toggleable_button.label_cpp').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
//]]>
</script>
</body>
</html>
