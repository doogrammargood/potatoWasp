<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.12"/>
<title>OpenCV: High Dynamic Range (HDR)</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.2.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<script type="text/javascript">
//<![CDATA[
function getLabelName(innerHTML) {
    var str = innerHTML.toLowerCase();
    // Replace all '+' with 'p'
    str = str.split('+').join('p');
    // Replace all ' ' with '_'
    str = str.split(' ').join('_');
    // Replace all '#' with 'sharp'
    str = str.split('#').join('sharp');
    // Replace other special characters with 'ascii' + code
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        if (!(charCode == 95 || (charCode > 96 && charCode < 123) || (charCode > 47 && charCode < 58)))
            str = str.substr(0, i) + 'ascii' + charCode + str.substr(i + 1);
    }
    return str;
}
function addToggle() {
    var $getDiv = $('div.newInnerHTML').last();
    var buttonName = $getDiv.html();
    var label = getLabelName(buttonName.trim());
    $getDiv.attr("title", label);
    $getDiv.hide();
    $getDiv = $getDiv.next();
    $getDiv.attr("class", "toggleable_div label_" + label);
    $getDiv.hide();
}
//]]>
</script>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.12 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d6/d00/tutorial_py_root.html">OpenCV-Python Tutorials</a></li><li class="navelem"><a class="el" href="../../d0/d07/tutorial_py_table_of_contents_photo.html">Computational Photography</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">High Dynamic Range (HDR) </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Goal </h2>
<p>In this chapter, we will</p>
<ul>
<li>Learn how to generate and display HDR image from an exposure sequence.</li>
<li>Use exposure fusion to merge an exposure sequence.</li>
</ul>
<h2>Theory </h2>
<p>High-dynamic-range imaging (HDRI or HDR) is a technique used in imaging and photography to reproduce a greater dynamic range of luminosity than is possible with standard digital imaging or photographic techniques. While the human eye can adjust to a wide range of light conditions, most imaging devices use 8-bits per channel, so we are limited to only 256 levels. When we take photographs of a real world scene, bright regions may be overexposed, while the dark ones may be underexposed, so we can’t capture all details using a single exposure. HDR imaging works with images that use more than 8 bits per channel (usually 32-bit float values), allowing much wider dynamic range.</p>
<p>There are different ways to obtain HDR images, but the most common one is to use photographs of the scene taken with different exposure values. To combine these exposures it is useful to know your camera’s response function and there are algorithms to estimate it. After the HDR image has been merged, it has to be converted back to 8-bit to view it on usual displays. This process is called tonemapping. Additional complexities arise when objects of the scene or camera move between shots, since images with different exposures should be registered and aligned.</p>
<p>In this tutorial we show 2 algorithms (Debvec, Robertson) to generate and display HDR image from an exposure sequence, and demonstrate an alternative approach called exposure fusion (Mertens), that produces low dynamic range image and does not need the exposure times data. Furthermore, we estimate the camera response function (CRF) which is of great value for many computer vision algorithms. Each step of HDR pipeline can be implemented using different algorithms and parameters, so take a look at the reference manual to see them all.</p>
<h2>Exposure sequence HDR </h2>
<p>In this tutorial we will look on the following scene, where we have 4 exposure images, with exposure times of: 15, 2.5, 1/4 and 1/30 seconds. (You can download the images from <a href="https://en.wikipedia.org/wiki/High-dynamic-range_imaging">Wikipedia</a>)</p>
<div class="image">
<img src="../../exposures.jpg" alt="exposures.jpg"/>
<div class="caption">
image</div></div>
 <h3>1. Loading exposure images into a list</h3>
<p>The first stage is simply loading all images into a list. In addition, we will need the exposure times for the regular HDR algorithms. Pay attention for the data types, as the images should be 1-channel or 3-channels 8-bit (np.uint8) and the exposure times need to be float32 and in seconds.</p>
<div class="fragment"><div class="line"><span class="keyword">import</span> cv2</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Loading exposure images into a list</span></div><div class="line">img_fn = [<span class="stringliteral">&quot;img0.jpg&quot;</span>, <span class="stringliteral">&quot;img1.jpg&quot;</span>, <span class="stringliteral">&quot;img2.jpg&quot;</span>, <span class="stringliteral">&quot;img3.jpg&quot;</span>]</div><div class="line">img_list = [cv2.imread(fn) <span class="keywordflow">for</span> fn <span class="keywordflow">in</span> img_fn]</div><div class="line">exposure_times = np.array([15.0, 2.5, 0.25, 0.0333], dtype=np.float32)</div></div><!-- fragment --><h3>2. Merge exposures into HDR image</h3>
<p>In this stage we merge the exposure sequence into one HDR image, showing 2 possibilities which we have in OpenCV. The first method is Debvec and the second one is Robertson. Notice that the HDR image is of type float32, and not uint8, as it contains the full dynamic range of all exposure images.</p>
<div class="fragment"><div class="line"><span class="comment"># Merge exposures to HDR image</span></div><div class="line">merge_debvec = cv2.createMergeDebevec()</div><div class="line">hdr_debvec = merge_debvec.process(img_list, times=exposure_times.copy())</div><div class="line">merge_robertson = cv2.createMergeRobertson()</div><div class="line">hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy())</div></div><!-- fragment --><h3>3. Tonemap HDR image</h3>
<p>We map the 32-bit float HDR data into the range [0..1]. Actually, in some cases the values can be larger than 1 or lower the 0, so notice we will later have to clip the data in order to avoid overflow.</p>
<div class="fragment"><div class="line"><span class="comment"># Tonemap HDR image</span></div><div class="line">tonemap1 = cv2.createTonemapDurand(gamma=2.2)</div><div class="line">res_debvec = tonemap1.process(hdr_debvec.copy())</div><div class="line">tonemap2 = cv2.createTonemapDurand(gamma=1.3)</div><div class="line">res_robertson = tonemap2.process(hdr_robertson.copy())</div></div><!-- fragment --><h3>4. Merge exposures using Mertens fusion</h3>
<p>Here we show an alternative algorithm to merge the exposure images, where we do not need the exposure times. We also do not need to use any tonemap algorithm because the Mertens algorithm already gives us the result in the range of [0..1].</p>
<div class="fragment"><div class="line"><span class="comment"># Exposure fusion using Mertens</span></div><div class="line">merge_mertens = cv2.createMergeMertens()</div><div class="line">res_mertens = merge_mertens.process(img_list)</div></div><!-- fragment --><h3>5. Convert to 8-bit and save</h3>
<p>In order to save or display the results, we need to convert the data into 8-bit integers in the range of [0..255].</p>
<div class="fragment"><div class="line"><span class="comment"># Convert datatype to 8-bit and save</span></div><div class="line">res_debvec_8bit = np.clip(res_debvec*255, 0, 255).astype(<span class="stringliteral">&#39;uint8&#39;</span>)</div><div class="line">res_robertson_8bit = np.clip(res_robertson*255, 0, 255).astype(<span class="stringliteral">&#39;uint8&#39;</span>)</div><div class="line">res_mertens_8bit = np.clip(res_mertens*255, 0, 255).astype(<span class="stringliteral">&#39;uint8&#39;</span>)</div><div class="line"></div><div class="line">cv2.imwrite(<span class="stringliteral">&quot;ldr_debvec.jpg&quot;</span>, res_debvec_8bit)</div><div class="line">cv2.imwrite(<span class="stringliteral">&quot;ldr_robertson.jpg&quot;</span>, res_robertson_8bit)</div><div class="line">cv2.imwrite(<span class="stringliteral">&quot;fusion_mertens.jpg&quot;</span>, res_mertens_8bit)</div></div><!-- fragment --><h2>Results </h2>
<p>You can see the different results but consider that each algorithm have additional extra parameters that you should fit to get your desired outcome. Best practice is to try the different methods and see which one performs best for your scene.</p>
<h3>Debvec:</h3>
<div class="image">
<img src="../../ldr_debvec.jpg" alt="ldr_debvec.jpg"/>
<div class="caption">
image</div></div>
 <h3>Robertson:</h3>
<div class="image">
<img src="../../ldr_robertson.jpg" alt="ldr_robertson.jpg"/>
<div class="caption">
image</div></div>
 <h3>Mertenes Fusion:</h3>
<div class="image">
<img src="../../fusion_mertens.jpg" alt="fusion_mertens.jpg"/>
<div class="caption">
image</div></div>
<h2>Estimating Camera Response Function </h2>
<p>The camera response function (CRF) gives us the connection between the scene radiance to the measured intensity values. The CRF if of great importance in some computer vision algorithms, including HDR algorithms. Here we estimate the inverse camera response function and use it for the HDR merge.</p>
<div class="fragment"><div class="line"><span class="comment"># Estimate camera response function (CRF)</span></div><div class="line">cal_debvec = cv2.createCalibrateDebevec()</div><div class="line">crf_debvec = cal_debvec.process(img_list, times=exposure_times)</div><div class="line">hdr_debvec = merge_debvec.process(img_list, times=exposure_times.copy(), response=crf_debvec.copy())</div><div class="line">cal_robertson = cv2.createCalibrateRobertson()</div><div class="line">crf_robertson = cal_robertson.process(img_list, times=exposure_times)</div><div class="line">hdr_robertson = merge_robertson.process(img_list, times=exposure_times.copy(), response=crf_robertson.copy())</div></div><!-- fragment --><p>The camera response function is represented by a 256-length vector for each color channel. For this sequence we got the following estimation:</p>
<div class="image">
<img src="../../crf.jpg" alt="crf.jpg"/>
<div class="caption">
image</div></div>
 <h2>Additional Resources </h2>
<ol type="1">
<li>Paul E Debevec and Jitendra Malik. Recovering high dynamic range radiance maps from photographs. In ACM SIGGRAPH 2008 classes, page 31. ACM, 2008.</li>
<li>Mark A Robertson, Sean Borman, and Robert L Stevenson. Dynamic range improvement through multiple exposures. In Image Processing, 1999. ICIP 99. Proceedings. 1999 International Conference on, volume 3, pages 159–163. IEEE, 1999.</li>
<li>Tom Mertens, Jan Kautz, and Frank Van Reeth. Exposure fusion. In Computer Graphics and Applications, 2007. PG'07. 15th Pacific Conference on, pages 382–390. IEEE, 2007.</li>
<li>Images from <a href="https://en.wikipedia.org/wiki/High-dynamic-range_imaging">Wikipedia-HDR</a></li>
</ol>
<h2>Exercises </h2>
<ol type="1">
<li>Try all tonemap algorithms: <a href="http://docs.opencv.org/master/da/d53/classcv_1_1TonemapDrago.html">Drago</a>, <a href="http://docs.opencv.org/master/da/d3d/classcv_1_1TonemapDurand.html">Durand</a>, <a href="http://docs.opencv.org/master/de/d76/classcv_1_1TonemapMantiuk.html">Mantiuk</a> and <a href="http://docs.opencv.org/master/d0/dec/classcv_1_1TonemapReinhard.html">Reinhard</a>.</li>
<li>Try changing the parameters in the HDR calibration and tonemap methods. </li>
</ol>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Fri Dec 23 2016 13:00:25 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.12
</small></address>
<script type="text/javascript">
//<![CDATA[
function addButton(label, buttonName) {
    var b = document.createElement("BUTTON");
    b.innerHTML = buttonName;
    b.setAttribute('class', 'toggleable_button label_' + label);
    b.onclick = function() {
        $('.toggleable_button').css({
            border: '2px outset',
            'border-radius': '4px'
        });
        $('.toggleable_button.label_' + label).css({
            border: '2px inset',
            'border-radius': '4px'
        });
        $('.toggleable_div').css('display', 'none');
        $('.toggleable_div.label_' + label).css('display', 'block');
    };
    b.style.border = '2px outset';
    b.style.borderRadius = '4px';
    b.style.margin = '2px';
    return b;
}
function buttonsToAdd($elements, $heading, $type) {
    if ($elements.length === 0) {
        $elements = $("" + $type + ":contains(" + $heading.html() + ")").parent().prev("div.newInnerHTML");
    }
    var arr = jQuery.makeArray($elements);
    var seen = {};
    arr.forEach(function(e) {
        var txt = e.innerHTML;
        if (!seen[txt]) {
            $button = addButton(e.title, txt);
            if (Object.keys(seen).length == 0) {
                var linebreak1 = document.createElement("br");
                var linebreak2 = document.createElement("br");
                ($heading).append(linebreak1);
                ($heading).append(linebreak2);
            }
            ($heading).append($button);
            seen[txt] = true;
        }
    });
    return;
}
$("h2").each(function() {
    $heading = $(this);
    $smallerHeadings = $(this).nextUntil("h2").filter("h3").add($(this).nextUntil("h2").find("h3"));
    if ($smallerHeadings.length) {
        $smallerHeadings.each(function() {
            var $elements = $(this).nextUntil("h3").filter("div.newInnerHTML");
            buttonsToAdd($elements, $(this), "h3");
        });
    } else {
        var $elements = $(this).nextUntil("h2").filter("div.newInnerHTML");
        buttonsToAdd($elements, $heading, "h2");
    }
});
$(".toggleable_button").first().click();
var $clickDefault = $('.toggleable_button.label_python').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
$clickDefault = $('.toggleable_button.label_cpp').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
//]]>
</script>
</body>
</html>
